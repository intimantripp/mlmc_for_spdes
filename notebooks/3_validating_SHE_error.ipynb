{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14e157c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "sys.path.insert(0, str(Path().resolve().parent))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ec74a3",
   "metadata": {},
   "source": [
    "### Proving error in estimating variance of Fourier mode using finite difference SHE\n",
    "\n",
    "This notebook will be used to outline the proof that using my finite difference scheme to obtain estimates of $\\mathbb{V}\\left[u_n(t)\\right]$, i.e. the $n$-th Fourier mode of $u(x,t)$ has error $|\\mathbb{V}\\left[u_n(t)\\right] - \\mathbb{V}\\left[\\hat{u}_n(t)\\right]| \\sim O(\\Delta x^2)$. \n",
    "\n",
    "I'll begin by reviewing the quantity I'm trying to derive. Fourier modes are found via the following relationships:\n",
    "$$\n",
    "u(x,t) = \\sum_{n=0}^\\infty u_n(t) \\phi_n(x) \\\\\n",
    "\\phi_n(x) = \\sqrt{2} \\sin(n \\pi x), \\quad \\langle \\phi_n, \\phi_m \\rangle = \\delta_{n,m} \\\\\n",
    "u_n(t) = \\langle u(x,t), \\phi_n \\rangle = \\int_0^1 u(x,t) \\phi_n(x) dx \\\\\n",
    "u_n(t) \\sim \\mathcal{N}(0,\\frac{1 - e^{-2\\lambda_n^2t}}{2\\lambda_n^2}), \\quad \\lambda_n = \\pi^2 n^2 \\\\\n",
    "\\lim_{t \\to \\infty}\\mathbb{V}\\left[u_n\\right] = \\frac{1}{2\\lambda_n^2} \\quad (*)\n",
    "$$\n",
    "So the long term true variance of our quantity of interest is $(*)$.\n",
    "\n",
    "Now let's examine what we are doing in our discrete approximation of the above operations.\n",
    "At this point getting a good notation is going to be really important too. I discretise the spatial domain $[0,1]$ into $N+2$ points, equivalently $N+1$ subdivisions, each of width $\\Delta x = \\frac{1}{N+1}$. This means we have $N$ internal points. Each discrete spatial point is notated as $x_i$, corresponding to the $i \\Delta x = \\frac{i}{N+1}$ where $i \\in \\{0, 1, ..., N+1\\}$. Similarly, we discretise our temporal grid. We have $\\Delta t = \\lambda \\Delta x^2, \\quad t_j = j \\Delta t, \\quad j \\in \\{0, 1, 2, ...\\}$. We express our discretised points of u(x_i, t_j) using the following notation: $u(x_i, t_j) := u_i^j$. Finally, my finite volume derived scheme for the SHE is the following\n",
    "\n",
    "$$\n",
    "u_i^{j+1} =  u_i^j + \\frac{\\Delta t}{\\Delta x^2} \\left(u_{i+1}^j - 2u_i^j + u_{i-1}^j\\right) + \\sqrt{\\frac{\\Delta t}{\\Delta x}} Z_i^j, \\quad Z_i^j \\sim \\mathcal{N}(0, 1)\\\\\n",
    "\\text{with boundary conditions:} \\quad u_0^j = u_N^j = 0, \\quad u_i^0 = 0\n",
    "$$\n",
    "\n",
    "Now, what I will be doing is copying the sequence of operations I used to derive the Fourier mode in the continuous case, but this time in the discrete equivalent case, and in this way I shall be able to demonstrate the consistency error in the results. As we're now in discrete space, I'll move to describing things using vectors and matrices. A better notation now becomes $\\bar{u}^j := (u_0^j, u_1^j, ..., u_{N+1}^j)^T$. The basis functions become basis vectors in the new space, as we've discretised. $(\\phi_n)_i = \\sqrt{2} \\sin(n \\pi x_i)$, $\\bar{\\phi}_n = \\sqrt{2}(\\sin(n \\pi x_1), \\sin(n \\pi x_2), ..., \\sin(n \\pi x_N))^T$ In matrix vector form the finite difference scheme now becomes:\n",
    "\n",
    "$$\n",
    "\\bar{u}^j = \\begin{bmatrix}\n",
    "u_1^j \\\\\n",
    "u_2^j \\\\\n",
    "\\vdots \\\\\n",
    "u_N^j\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^N, \\quad \n",
    "Z^j =\n",
    "\\begin{bmatrix}\n",
    "Z_1^j \\\\\n",
    "Z_2^j \\\\\n",
    "\\vdots \\\\\n",
    "Z_N^j\n",
    "\\end{bmatrix}\n",
    "\\sim \\mathcal{N}(0, I_N), \\quad\n",
    "\\bar{\\phi}_n = \\sqrt{2}\n",
    "\\begin{bmatrix}\n",
    "\\sin\\left( \\frac{n \\pi}{N+1} \\cdot 1 \\right) \\\\\n",
    "\\sin\\left( \\frac{n \\pi}{N+1} \\cdot 2 \\right) \\\\\n",
    "\\vdots \\\\\n",
    "\\sin\\left( \\frac{n \\pi}{N+1} \\cdot N \\right)\n",
    "\\end{bmatrix}\n",
    "\\in \\mathbb{R}^N \\\\\n",
    "\n",
    "\n",
    "\\bar{u}^{j+1} = \\bar{u}^j + \\Delta t A\\bar{u}^j + \\sqrt{\\frac{\\Delta t}{\\Delta x}} Z^j\\\\\n",
    "\\text{where } \\quad A = \\frac{1}{\\Delta x^2} \\begin{bmatrix}\n",
    "-2 & 1 & & \\\\\n",
    "1 & -2 & 1 & \\\\\n",
    "& \\ddots & \\ddots & \\ddots \\\\\n",
    "& & 1 & -2\n",
    "\\end{bmatrix} \\\\\n",
    "\\text{Importantly, we now just consider the internal points for the above. So } i \\in \\{1, 2, ..., N\\}.\n",
    "\\text{What's kind of neat now is that the Fourier decomposition becomes: }\\\\\n",
    "\\bar{u}^j = \\sum_{n=1}^{N}\\hat{u}_n^j \\bar{\\phi}_n\\\\\n",
    "\\text{i.e. we can express $\\bar{u}^j$ as a combination of our $N$ basis vectors scaled by Fourier modes.}\\\\\n",
    "\\text{This is what Prof. Giles was referring to when he said I can express $u_i^j$ as a finite sum.}\n",
    "$$ \n",
    "\n",
    "From the NSPDEs course, Süli introduced the discrete inner product to us. It was: $\\left(V, W\\right)_h := \\sum_{i=1}^{N} h V_i W_i$.\n",
    "This is the same thing we can use for obtaining our discrete Fourier modes. So, we will do the same series of operations now:\n",
    "\n",
    "$$\n",
    "\\bar{u}^{j+1} = \\bar{u}^j + \\Delta t A\\bar{u}^j + \\sqrt{\\frac{\\Delta t}{\\Delta x}} Z^j \\\\\n",
    "\\text{Orthogonality of basis functions: } (\\bar{\\phi}_n, \\bar{\\phi}_m)_h := \\sum_{i=1}^{N} \\Delta x \\cdot \\phi_n(x_i) \\cdot \\phi_m(x_i) = \\boxed{\n",
    "\\begin{cases}\n",
    "0, & \\text{if } n \\ne m \\\\\n",
    "1, & \\text{if } n = m\n",
    "\\end{cases}\n",
    "}\\\\\n",
    "\\text{As we have this result from the theory of discrete sine transforms: }\n",
    "\\sum_{i=1}^{N}\n",
    "\\sin\\left( \\frac{n \\pi i}{N+1} \\right)\n",
    "\\cdot\n",
    "\\sin\\left( \\frac{m \\pi i}{N+1} \\right)\n",
    "=\n",
    "\\begin{cases}\n",
    "\\frac{N+1}{2}, & \\text{if } n = m \\\\\n",
    "0, & \\text{if } n \\ne m\n",
    "\\end{cases}\\\\\n",
    "\\text{So let's apply that result to our discrete approximations: }\n",
    "(\\bar{u}^{j+1}, \\bar{\\phi}_n)_h = (\\bar{u}^j, \\bar{\\phi}_n)_h + \\Delta t (A \\bar{u}^j, \\bar{\\phi}_n)_h + \\sqrt{ \\frac{\\Delta t}{\\Delta x} } (Z^j, \\bar{\\phi}_n)_h\\\\\n",
    "\\text{LHS: } (\\bar{u}^{j+1}, \\bar{\\phi}_n)_h = \\left(\\sum_{k=1}^{N}\\hat{u}_k^{j+1} \\bar{\\phi}_k, \\bar{\\phi}_n\\right)_h = \\hat{u}_n^{j+1}\\\\\n",
    "\\text{RHS, first term: } (\\bar{u}^j, \\bar{\\phi}_n)_h = \\hat{u}_n^{j}\\\\\n",
    "\\text{RHS, second term: } \\Delta t (A \\bar{u}^j, \\bar{\\phi}_n)_h = \\Delta t \\Delta x \\left(A \\bar{u}^j\\right)^T \\bar{\\phi}_n = \\Delta t \\Delta x (\\bar{u}^j)^T A^T \\bar{\\phi}_n = \\Delta t \\Delta x (\\bar{u}^j)^T A \\bar{\\phi}_n\\\\\n",
    "$$\n",
    "\n",
    "Now, $A$ is a symmetric matrix, and $\\bar{\\phi}_n$ are actually eigenvectors\n",
    "(see [Wikipedia](https://en.wikipedia.org/wiki/Eigenvalues_and_eigenvectors_of_the_second_derivative#Pure_Dirichlet_boundary_conditions_2)).\n",
    "\n",
    "The eigenvalues of $A$ are given by: $-\\lambda_n^{FD} = -\\frac{4}{\\Delta x^2} \\sin^2\\left( \\frac{\\pi n}{2(N+1)} \\right)$. So $A \\bar{\\phi}_n = -\\lambda_n^{FD} \\bar{\\phi}_n$. Returning to our calculations:\n",
    "\n",
    "$$\n",
    "\\Delta t \\Delta x (\\bar{u}^j)^T A \\bar{\\phi}_n = \\Delta t \\Delta x (\\bar{u}^j)^T \\lambda_n \\bar{\\phi}_n = \\Delta t \\lambda_n^{FD} \\left(\\bar{u}^j, \\bar{\\phi}_n\\right) = -\\Delta t \\lambda_n^{FD} \\hat{u}_n^j\\\\\n",
    "\\text{That's neat. Final RHS term: } \\sqrt{ \\frac{\\Delta t}{\\Delta x} } (Z^j, \\bar{\\phi}_n)_h = \\sqrt{ \\frac{\\Delta t}{\\Delta x} } \\sum_{k=1}^N \\Delta x Z_k^j (\\bar{\\phi}^j)_k \\quad \\text{And this is a normal RV. Sum of normals.}\n",
    " $$\n",
    "\n",
    " So our final result is:\n",
    "$$\n",
    "(\\bar{u}^{j+1}, \\bar{\\phi}_n)_h = (\\bar{u}^j, \\bar{\\phi}_n)_h + \\Delta t (A \\bar{u}^j, \\bar{\\phi}_n)_h + \\sqrt{ \\frac{\\Delta t}{\\Delta x} } (Z^j, \\bar{\\phi}_n)_h \\\\\n",
    "\\boxed{\n",
    "\\hat{u}_n^{j+1} = (1 - \\Delta t \\lambda_n^{FD}) \\hat{u}_n^j + \\sqrt{ \\frac{\\Delta t}{\\Delta x} } (Z^j, \\bar{\\phi}_n)_h\n",
    "}\\\\\n",
    "\\text{This is our expression for Fourier modes. Now we'll do some analysis on the thing.}\n",
    "$$\n",
    "\n",
    "## Stationary Variance of the Discrete Fourier Mode\n",
    "\n",
    "We'll analyse the stationary variance of $\\hat{u}_n^j$ as $j \\to \\infty$ . The equation:\n",
    "\n",
    "$$\n",
    "\\hat{u}_n^{j+1} = (1 - \\Delta t \\lambda_n^{FD}) \\hat{u}_n^j + \\sqrt{ \\frac{\\Delta t}{\\Delta x} } (Z^j, \\bar{\\phi}_n)_h\n",
    "$$\n",
    "\n",
    "Define the random noise term as:\n",
    "\n",
    "$$\n",
    "\\eta_n^j := \\sqrt{ \\frac{\\Delta t}{\\Delta x} } (Z^j, \\bar{\\phi}_n)_h = \\sqrt{ \\frac{\\Delta t}{\\Delta x} } \\sum_{i=1}^N \\Delta x \\cdot Z_i^j \\phi_n(x_i) = \\sqrt{ \\Delta t \\Delta x } \\sum_{i=1}^N Z_i^j \\phi_n(x_i)\n",
    "$$\n",
    "\n",
    "Since the $Z_i^j$ are i.i.d. $\\mathcal{N}(0,1)$, this is a weighted sum of independent Gaussians, so $\\eta_n^j \\sim \\mathcal{N}(0, \\sigma_n^2)$ where:\n",
    "\n",
    "$$\n",
    "\\sigma_n^2 = \\mathbb{V}[\\eta_n^j] = \\Delta t \\Delta x \\sum_{i=1}^N \\phi_n(x_i)^2 \\approx \\Delta t\n",
    "$$\n",
    "\n",
    "This approximation holds because:\n",
    "\n",
    "$$\n",
    "\\sum_{i=1}^N \\phi_n(x_i)^2 \\cdot \\Delta x \\approx \\int_0^1 \\phi_n(x)^2 dx = 1\n",
    "$$\n",
    "\n",
    "So we now have a scalar stochastic recurrence:\n",
    "\n",
    "$$\n",
    "\\hat{u}_n^{j+1} = a_n \\hat{u}_n^j + \\eta_n^j,\n",
    "\\quad \\text{with} \\quad a_n = 1 - \\Delta t \\lambda_n^{FD}, \\quad \\eta_n^j \\sim \\mathcal{N}(0, \\Delta t)\n",
    "$$\n",
    "\n",
    "This is a discrete-time Ornstein–Uhlenbeck process. Its stationary variance is fairly easy to derive. Just set both variances equal to each other (stationary case) and we obtain:\n",
    "\n",
    "$$\n",
    "\\mathbb{V}[\\hat{u}_n^\\infty] = \\frac{\\mathbb{V}[\\eta_n^j]}{1 - a_n^2}\n",
    "= \\frac{\\Delta t}{1 - (1 - \\Delta t \\lambda_n^{FD})^2}\n",
    "$$\n",
    "\n",
    "Now expand the denominator:\n",
    "\n",
    "$$\n",
    "1 - (1 - \\Delta t \\lambda_n^{FD})^2 = 1 - \\left(1 - 2 \\Delta t \\lambda_n^{FD} + \\Delta t^2 (\\lambda_n^{FD})^2 \\right)\n",
    "= 2 \\Delta t \\lambda_n^{FD} - \\Delta t^2 (\\lambda_n^{FD})^2\n",
    "$$\n",
    "\n",
    "So:\n",
    "\n",
    "$$\n",
    "\\mathbb{V}[\\hat{u}_n^\\infty] = \\frac{\\Delta t}{2 \\Delta t \\lambda_n^{FD} - \\Delta t^2 (\\lambda_n^{FD})^2}\n",
    "= \\frac{1}{2 \\lambda_n^{FD} - \\Delta t \\lambda_n^{FD^2}} = \\frac{1}{2\\lambda_n^{FD}(1 - \\frac{\\Delta t \\lambda_n^{FD}}{2})}\n",
    "$$\n",
    "\n",
    "Now do a Taylor expansion of the denominator using $\\frac{1}{1-x} = 1 + x + x^2 + x^3 ...$:\n",
    "$$\n",
    "\\mathbb{V}[\\hat{u}_n^\\infty] = \\frac{1}{2\\lambda_n^{FD}}(1 + \\frac{\\Delta t \\lambda_n^{FD}}{2} ...)\\\\\n",
    "\\text{Remembering what $\\lambda_n^{FD}$ is: } \\lambda_n^{FD} = \\frac{4}{\\Delta x^2} \\sin^2\\left(\\frac{n\\pi}{2\\left(N+1\\right)}\\right) = \\frac{4}{\\Delta x^2} \\sin^2\\left(n \\pi \\Delta x \\right)\\\\\n",
    "\\\\\n",
    "\\text{Another Taylor expansion } \\sin(\\frac{n \\pi \\Delta x}{2}) = \\frac{n \\pi \\Delta x}{2} - \\frac{1}{6} (\\frac{n \\pi \\Delta x}{2})^3 \\dots\\\\\n",
    "\\\\\n",
    "\\sin^2(n \\pi \\Delta x) = \\frac{n^2 \\pi^2 \\Delta x^2}{4} + \\mathcal{O}(\\Delta x^4)\\\\\n",
    "\\lambda_n^{FD} =  \\frac{4}{\\Delta x^2} \\sin^2\\left( \\frac{n\\pi}{2\\left( N+1 \\right)} \\right) = \\frac{4}{\\Delta x^2} (\\frac{n^2 \\pi^2 \\Delta x^2}{4} + \\mathcal{O}(\\Delta x^4)) = n^2 \\pi^2  + \\mathcal{O}(\\Delta x^2) = \\lambda_n^2 + \\mathcal{O}(\\Delta x^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8478da",
   "metadata": {},
   "source": [
    "Really, really close now.\n",
    "\n",
    "So, we have that $\\lambda_n^{FD} = \\lambda_n^2 + \\mathcal{O}(\\Delta x^2)$. This is nice. We also had that $\\mathbb{V}\\left[\\hat{u}_n^\\infty\\right] = \\frac{1}{2\\lambda_n^{FD}}\\left(1 + \\frac{\\Delta t \\lambda_n^{FD}}{2} + \\dots\\right)$.\n",
    "\n",
    "Little bit of Taylor expanding and reorgaising should show that I the right result :). \n",
    "\n",
    "$$\n",
    "\\mathbb{V}\\left[\\hat{u}_n^\\infty\\right] = \\frac{1}{2\\lambda_n^{FD}}\\left(1 + \\frac{\\Delta t \\lambda_n^{FD}}{2} + \\dots\\right) \\\\\n",
    " = \\frac{1}{2\\left(\\lambda_n^2 + \\mathcal{O}(\\Delta x^2)\\right)}\\left(1 + \\frac{\\Delta t \\lambda_n^{FD}}{2} + \\dots\\right) \\\\\n",
    " = \\frac{1}{2 \\lambda_n^2 \\left(1 + \\mathcal{O}(\\Delta x^2)\\right)}\\left(1 + \\frac{\\Delta t \\lambda_n^{FD}}{2} + \\dots\\right) \\\\\n",
    " = \\frac{1}{2 \\lambda_n^2}\\left(1 + \\mathcal{O}(\\Delta x^2)\\right)\\left(1 + \\frac{\\Delta t \\lambda_n^{FD}}{2} + \\dots\\right) \\\\\n",
    " = \\frac{1}{2 \\lambda_n^2}\\left(1 + \\mathcal{O}(\\Delta x^2)\\right)\n",
    "$$\n",
    "\n",
    "And so we compare to the original, remember $(*)$ equation at the beginning, $\\mathbb{V}\\left[u_n^\\infty\\right] = \\frac{1}{2\\lambda_n^2}$\n",
    "\n",
    "$$\n",
    "|\\mathbb{V}\\left[u_n^\\infty\\right] - \\mathbb{V}\\left[\\hat{u}_n^\\infty]\\right]| = |\\frac{1}{2\\lambda_n^2} - \\frac{1}{2 \\lambda_n^2}\\left(1 + \\mathcal{O}(\\Delta x^2)\\right)|\n",
    "= \\mathcal{O}(\\Delta x^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6478ec90",
   "metadata": {},
   "source": [
    "#### Trying to derive Variance Decay for variance of Fourier Amplitude\n",
    "\n",
    "I'm beginning by reviewing some of the quantities I derived before:\n",
    "\n",
    "• The $n$-th finite difference approximated Fourier mode is normally distributed, with a stationary distribution $\\hat{u}_n \\sim \\mathcal{N}\\left(0, \\frac{1}{2\\lambda_n^{FD}-\\Delta t (\\lambda_n^{FD})^2}\\right)$ \\\n",
    "• This is in contrast to the continuous Fourier mode which has distribution $u_n \\sim \\mathcal{N}\\left(0, \\frac{1}{2\\lambda_n}\\right)$, where $\\lambda_n = n^2 \\pi^2$.\\\n",
    "• $\\lambda_n^{FD} = \\frac{4}{\\Delta x^2}\\sin^2\\left(\\frac{n \\pi \\Delta x}{2}\\right) = \\frac{4}{\\Delta x^2} \\left(\\frac{n^2\\pi^2 \\Delta x^2}{4} - \\frac{\\pi^4n^4\\Delta x^4}{48} + \\mathcal{O}(\\Delta x^6)\\right) =  \\lambda_n - a \\Delta x^2 + \\mathcal{O}(\\Delta x^4)$ where $a = \\frac{\\pi^4n^4}{12}$\\\n",
    "• Some points on convention. In the MLMC estimator I have $\\hat{u}_n$'s with different $\\Delta x$'s. I'm going to start using $h$ for the spatial step because it's less typing in markdown. There are two widths, $h_l$ and $h_{l-1}$. In this MLMC implementation they're related through the following: $h_l = 2^{-(l+1)}$. This means $h_{l-1} = 2h_l$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490788e2",
   "metadata": {},
   "source": [
    "To begin I'm going to expand the variance of $\\hat{u}$.\n",
    "\n",
    "$$\n",
    "\\mathbb{V}[\\hat{u}_n] = \\frac{1}{2 \\lambda_n^{FD} - \\Delta t (\\lambda_n^{FD})^2} \\quad \\Delta t = C h^2 \\text{   where C is CFL num}\\\\\n",
    "(\\lambda_n^{FD})^2 = (\\lambda_n - ah^2 + \\mathcal{O}(h^4))^2 = \\lambda_n^2 - 2a\\lambda_nh^2 + \\mathcal{O}(h^4) \\\\\n",
    "\\text{So denominator is: }\\\\\n",
    "2\\lambda_n^{FD} - \\Delta t(\\lambda_n^{FD})^2 = 2(\\lambda_n - ah^2 + \\mathcal{O}(h^4)) - Ch^2(\\lambda_n^2 - 2a\\lambda_nh^2 + \\mathcal{O}(h^4)) \\\\\n",
    "= 2\\lambda_n - (2a + C\\lambda_n^2)h^2 + \\mathcal{O}(h^4)\\\\\n",
    "\\text{So now rewriting the variance: } \\\\\n",
    "\\mathbb{V}[\\hat{u}_n] = \\frac{1}{2 \\lambda_n^{FD} - \\Delta t (\\lambda_n^{FD})^2} = \\frac{1}{2\\lambda_n \\left(1 - \\frac{2a + C\\lambda_n^2}{2\\lambda_n}h^2 + \\mathcal{O}(h^4)\\right)} \\\\\n",
    "= \\frac{1}{2\\lambda_n}\\left(1 + \\frac{2a + C\\lambda_n^2}{2\\lambda_n} h^2 + \\mathcal{O}(h^4)\\right) \\\\\n",
    "\\boxed{\n",
    "  \\mathbb{V}[\\hat{u}_n] = \\frac{1}{2\\lambda_n}\n",
    "  +\n",
    "  \\underbrace{\\frac{2a + C\\lambda_n^2}{4\\lambda_n^2}}_{=\\,b} h^2\n",
    "  + \\mathcal{O}(h^4)\n",
    " = \\frac{1}{2\\lambda_n}\n",
    "  +\n",
    "  bh^2\n",
    "  + \\mathcal{O}(h^4)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6897179d",
   "metadata": {},
   "source": [
    "Next, I want to now derive the variances of estimators $\\hat{u}_n$ at different levels in terms of on another. I'm going to replace my $n$ subscript in $\\hat{u}_n$ with an $l$, as what I'm about to do can hold for any $n$-th Fourier mode, and I instead want to relate the levels of the Fourier modes to one another.\n",
    "$$\n",
    "\\mathbb{V}[\\hat{u}_{l}] = \\sigma_l^2 = \\frac{1}{2\\lambda_n} + bh_l^2 + \\mathcal{O}(h_l^4) \\\\\n",
    "\\mathbb{V}[\\hat{u}_{l-1}] = \\sigma_{l-1}^2 = \\frac{1}{2\\lambda_n} + bh_{l-1}^2 + \\mathcal{O}(h_{l-1}^4) = \\frac{1}{2\\lambda_n} + 4bh_{l}^2 + \\mathcal{O}(h_{l}^4) \\quad h_{l-1} = 2h_l\\\\\n",
    "\\text{A further relevant item } \\mathbb{V}[\\hat{u}_{l}] = \\mathbb{E}[\\hat{u}_l^2] - \\underbrace{\\mathbb{E}[\\hat{u}_l]^2}_{=\\.0}\\\\\n",
    "\\text{So } \\mathbb{V}[\\hat{u}_{l}] = \\mathbb{E}[\\hat{u}_l^2] = \\sigma_l^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b63714",
   "metadata": {},
   "source": [
    "Those will be important. Now let's look at what I'm trying to calculate.\n",
    "$$\n",
    "V_l = \\mathbb{V}\\left[P_l - P_{l-1}\\right] = \\mathbb{V}\\left[P_l\\right] + \\mathbb{V}[P_{l-1}] - 2 \\mathrm{Cov}(P_l, P_{l-1}).\n",
    "$$\n",
    "where $P_l = \\frac{1}{M}\\sum_{m=1}^M (\\hat{u}_l^{(m)})^2$. Let's look at each of those terms.\n",
    "\n",
    "$$\n",
    "\\mathbb{V}\\left[P_l\\right] = \\mathbb{V}\\left[\\frac{1}{M}\\sum_{m=1}^M (\\hat{u}_l^{(m)})^2 \\right] = \\frac{1}{M}\\mathbb{V}[\\hat{u}_l^2]\\\\\n",
    "\\mathbb{V}[\\hat{u}_l^2] = \\mathbb{E}[\\hat{u}_l^4] - \\mathbb{E}[\\hat{u}_l^2]^2\\\\\n",
    "\\text{Now $\\hat{u}$ is normally distributed and has mean 0, so we can use this identity: }\\\\ \n",
    "E[(X-\\mu)^4)] = 3\\sigma^4\\\\\n",
    "\\mathbb{V}[\\hat{u}_l^2] = 3\\sigma_l^4 - \\sigma_l^4 = 2\\sigma_l^4.\\\\\n",
    "\\text{So we obtain: }\\\\\n",
    "\\boxed{\\mathbb{V}[P_l] = \\frac{2\\sigma_l^4}{M} \\quad \\mathbb{V}[P_{l-1}] = \\frac{2\\sigma_{l-1}^4}{M}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04115272",
   "metadata": {},
   "source": [
    "Now to examine $\\mathrm{Cov}(P_l, P_{l-1})$. \n",
    "$$\n",
    "\\mathrm{Cov}(P_l, P_{l-1}) = \\frac{1}{M}\\mathrm{Cov}(\\hat{u}_l^2, \\hat{u}_{l-1}^2) = \\frac{1}{M}(\\mathbb{E}[\\hat{u}_l^2 \\hat{u}_{l-1}^2] - \\mathbb{E}[\\hat{u}_l^2]\\mathbb{E}[\\hat{u}_{l-1}^2])\\\\\n",
    "\\mathbb{E}[\\hat{u}_l^2]\\mathbb{E}[\\hat{u}_{l-1}^2]) = \\sigma_l^2 \\sigma_{l-1}^2\n",
    "$$\n",
    "To get $\\mathbb{E}[\\hat{u}_l^2 \\hat{u}_{l-1}^2]$ I (well, via ChatGPT) found a very helpful [theorem](https://en.wikipedia.org/wiki/Isserlis\\%27s\\_theorem) for the expectation of products of normal random variables.\n",
    "$$\n",
    "\\mathbb{E}[\\hat{u}_l^2 \\hat{u}_{l-1}^2] = \\mathbb{E}[\\hat{u}_l^2]\\mathbb{E}[\\hat{u}_{l-1}^2] + 2 \\mathbb{E}[\\hat{u}_{l}^2\\hat{u}_{l-1}^2] \\\\\n",
    "= \\sigma_l^2\\sigma_{l-1}^2 + 2\\mathbb{E}[\\hat{u}_{l}\\hat{u}_{l-1}]^2\\\\\n",
    "\\mathrm{Cov}(\\hat{u}_l, \\hat{u}_{l-1}) = \\mathbb{E}[\\hat{u}_l\\hat{u}_{l-1}] - \\underbrace{\\mathbb{E}[\\hat{u}_l]\\mathbb{E}[\\hat{u}_{l-1}]}_{=\\,0} = \\rho \\sigma_l \\sigma_{l-1}\\\\\n",
    "2\\mathbb{E}[\\hat{u}_{l}\\hat{u}_{l-1}]^2 = 2 \\rho^2 \\sigma_l^2 \\sigma_{l-1}^2.\\\\\n",
    "\\text{So we obtain: }\\\\\n",
    "\\mathbb{E}[\\hat{u}_l^2 \\hat{u_{l-1}^2}] = \\sigma_l^2 \\sigma_{l-1}^2 + 2 \\rho^2 \\sigma_l^2 \\sigma_{l-1}^2\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336cddeb",
   "metadata": {},
   "source": [
    "So we obtain:\n",
    "$$\n",
    "\\mathrm{Cov}(P_l, P_{l-1}) = \\frac{1}{M}((\\mathbb{E}[\\hat{u}_l^2 \\hat{u}_{l-1}^2] - \\mathbb{E}[\\hat{u}_l^2]\\mathbb{E}[\\hat{u}_{l-1}^2])) = \\frac{1}{M}(\\sigma_l^2 \\sigma_{l-1}^2 + 2\\rho^2\\sigma_l^2\\sigma_{l-1}^2 - \\sigma_l^2 \\sigma_{l-1}^2)\\\\\n",
    "\\boxed{\\mathrm{Cov}(P_l, P_{l-1}) = \\frac{2\\rho^2\\sigma_l^2\\sigma_{l-1}^2}{M}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e1136f",
   "metadata": {},
   "source": [
    "Putting those terms together:\n",
    "$$\n",
    "V_l = \\mathbb{V}[P_l] + \\mathbb{V}[P_{l-1}] - 2\\mathrm{Cov}(P_l, P_{l-1}) = \\frac{2}{M}(\\sigma_l^4 + \\sigma_{l-1}^4 - 2\\rho^2 \\sigma_l^2 \\sigma_{l-1}^2)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b2b163",
   "metadata": {},
   "source": [
    "Now let's examine each of those terms one by one. I'm going to replace $\\frac{1}{2\\lambda_n} = \\sigma^2$, as it is the variance of continuous Fourier mode $u_n$.\n",
    "$$\n",
    "\\sigma_l^4 = (\\sigma^2 + bh_l^2 + \\mathcal{O}(h_l^4))^2 = \\sigma^4 + 2 \\sigma^2 bh_l^2 + \\mathcal{O}(h_l^4)\\\\\n",
    "\\sigma_{l-1}^4 = (\\sigma^2 + 4bh_l^2 + \\mathcal{O}(h_l^4))^2 = \\sigma^4 + 8\\sigma^2 bh_l^2 + \\mathcal{O}(h^4)\\\\\n",
    "\\sigma_l^2 \\sigma_{l-1}^2 = (\\sigma^2 + bh_l^2 + \\mathcal{O}(h_l^4))(\\sigma^2 + 4bh_l^2 + \\mathcal{O}(h_l^4)) = \\sigma^4 + 5\\sigma^2bh_l^2+ \\mathcal{O}(h^4)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017df17a",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma_l^4 + \\sigma_{l-1}^4 - 2\\rho^2\\sigma_l^2\\sigma_{l-1}^2 = 2\\sigma^2 + 10\\sigma^2bh_l^2 - 2\\rho^2(\\sigma^4 + 5\\sigma^2bh_l^2) + \\mathcal{O}(h_l^4)\\\\\n",
    "= 2 \\sigma^4 - 2\\rho^2\\sigma^2 + 10\\sigma^2 bh^2 - 10\\rho^2 \\sigma^2bh_l^2 + \\mathcal{O}(h_l^4)\\\\\n",
    "= 2\\sigma^4(1-\\rho^2) + 10\\sigma^2bh_l^2(1 - \\rho^2) + \\mathcal{O}(h_l^4)\\\\\n",
    "= O(h_l^4) \\quad \\text{   iff   } \\quad \\rho = \\pm 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73cc7b36",
   "metadata": {},
   "source": [
    "Convinced?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373f413d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlmc_venv (3.13.1)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
